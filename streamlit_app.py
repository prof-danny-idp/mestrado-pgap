import streamlit as st
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# --- Configura√ß√µes da P√°gina ---
st.set_page_config(
    page_title="Previsor de Evas√£o Escolar",
    page_icon="üéì",
    layout="wide"
)

# --- T√≠tulo e Informa√ß√µes ---
st.title('üéì Previsor de Evas√£o Escolar')
st.info('Este aplicativo utiliza Machine Learning para prever a probabilidade de evas√£o escolar de um aluno.')

# --- Carregamento dos Dados ---
@st.cache_data # Cacheia o carregamento dos dados para melhor performance
def load_data(url):
    try:
        df = pd.read_csv(url)
        return df
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {e}")
        st.warning("Por favor, verifique a URL do dataset ou a conex√£o com a internet.")
        return None

data_url = 'https://raw.githubusercontent.com/prof-danny-idp/machinelearning/refs/heads/main/evasao_escolar.csv'
df_raw = load_data(data_url)

if df_raw is not None:
    st.success(f"Dataset carregado com sucesso! ({df_raw.shape[0]} linhas, {df_raw.shape[1]} colunas)")

    # --- Explora√ß√£o dos Dados ---
    with st.expander("üîç Explorar os Dados Carregados"):
        st.write('**Dados Brutos**')
        st.dataframe(df_raw.head(), use_container_width=True)

        # Assume que a √∫ltima coluna √© o target, ou especifique o nome
        target_column = 'Evasao_Confirmada' # Ou o nome correto da coluna alvo no seu CSV

        if target_column not in df_raw.columns:
            st.error(f"A coluna alvo '{target_column}' n√£o foi encontrada no dataset. Verifique o nome da coluna.")
            st.stop()

        st.write('**Vari√°veis Preditoras (X)**')
        X_display = df_raw.drop(target_column, axis=1)
        st.dataframe(X_display.head(), use_container_width=True)

        st.write(f'**Vari√°vel Alvo (y): {target_column}**')
        y_display = df_raw[target_column]
        st.dataframe(y_display.head(), use_container_width=True)
        st.write(f"Distribui√ß√£o da vari√°vel alvo: \n{y_display.value_counts(normalize=True) * 100} %")


    # --- Visualiza√ß√£o dos Dados ---
    with st.expander("üìä Visualiza√ß√£o dos Dados"):
        st.write("Selecione as vari√°veis para o gr√°fico de dispers√£o:")
        
        # Tenta encontrar colunas num√©ricas para os eixos do gr√°fico
        numeric_cols = X_display.select_dtypes(include=np.number).columns.tolist()
        
        if len(numeric_cols) >= 2:
            col1_vis, col2_vis = st.columns(2)
            with col1_vis:
                x_axis = st.selectbox('Eixo X', numeric_cols, index=0 if numeric_cols else None)
            with col2_vis:
                # Garante que y_axis seja diferente de x_axis, se poss√≠vel
                available_y_options = [col for col in numeric_cols if col != x_axis]
                y_axis_index = 0
                if len(available_y_options) > 1:
                     y_axis_index = 1 if len(available_y_options) >1 else 0

                y_axis = st.selectbox('Eixo Y', available_y_options, index=y_axis_index if available_y_options else None)

            if x_axis and y_axis:
                st.scatter_chart(data=df_raw, x=x_axis, y=y_axis, color=target_column, use_container_width=True)
            else:
                st.warning("N√£o h√° colunas num√©ricas suficientes para gerar o gr√°fico de dispers√£o.")
        else:
            st.info("Dataset n√£o possui colunas num√©ricas suficientes para um gr√°fico de dispers√£o padr√£o.")


    # --- Input das Features na Sidebar ---
    with st.sidebar:
        st.header('üìù Insira os Dados do Aluno:')

        # Valores padr√£o e limites baseados na discuss√£o anterior
        # √â importante que estes nomes de colunas correspondam aos do CSV
        # Se o CSV tiver nomes diferentes, ajuste aqui e no 'data' dict abaixo.

        reprovacoes = st.slider('Reprova√ß√µes Anteriores', 0, 5, 0, help="N√∫mero de vezes que o aluno foi reprovado anteriormente.")
        faltas = st.slider('Percentual de Faltas (%)', 0.0, 100.0, 10.0, step=0.5, help="Percentual de faltas no √∫ltimo per√≠odo letivo.")
        media_notas = st.slider('M√©dia de Notas Anterior', 0.0, 10.0, 7.0, step=0.1, help="M√©dia das notas do aluno no ano/per√≠odo anterior.")
        renda_sm = st.slider('Renda Familiar Per Capita (SM)', 0.1, 10.0, 1.0, step=0.1, help="Renda familiar dividida pelo n√∫mero de pessoas, em Sal√°rios M√≠nimos.")
        escol_resp = st.slider('Escolaridade do Respons√°vel (Anos)', 0, 20, 11, help="Anos de estudo completos do principal respons√°vel pelo aluno.")
        
        aluno_trabalha_sb = st.selectbox('Aluno Trabalha?', ('N√£o', 'Sim'), index=0, help="O aluno exerce alguma atividade remunerada?")
        
        distorcao = st.slider('Distor√ß√£o Idade-S√©rie (Anos)', 0, 10, 0, help="Diferen√ßa entre a idade do aluno e a idade esperada para sua s√©rie.")
        
        zona_urbana_sb = st.selectbox('Reside em Zona Urbana?', ('Rural', 'Urbana'), index=1, help="O aluno reside em √°rea urbana ou rural?")

        # Mapeamento para consist√™ncia com dados num√©ricos (se aplic√°vel no CSV)
        # Se o CSV j√° usa 'Sim'/'N√£o', 'Urbana'/'Rural', este mapeamento n√£o √© estritamente necess√°rio
        # antes do get_dummies, mas √© bom para clareza se quisermos for√ßar 0/1 antes.
        # No entanto, para alinhar com o exemplo dos pinguins, vamos manter como string
        # e deixar o get_dummies tratar.

        data_input = {
            'Reprovacoes_Anteriores': reprovacoes,
            'Percentual_Faltas_Ultimo_Periodo': faltas,
            'Media_Notas_Ano_Anterior': media_notas,
            'Renda_Familiar_Per_Capita_SM': renda_sm,
            'Escolaridade_Responsavel_Anos': escol_resp,
            'Aluno_Trabalha': aluno_trabalha_sb, # Mantido como string
            'Distorcao_Idade_Serie': distorcao,
            'Zona_Residencia_Urbana': zona_urbana_sb # Mantido como string
        }
        
        # Verificar se as colunas do input existem no X_display (features do CSV)
        missing_cols_input = [col for col in data_input.keys() if col not in X_display.columns]
        if missing_cols_input:
            st.error(f"Erro de Mapeamento de Colunas: As seguintes colunas do input n√£o existem no dataset carregado: {', '.join(missing_cols_input)}. Verifique os nomes das colunas no CSV e no c√≥digo.")
            st.stop()

        input_df = pd.DataFrame(data_input, index=[0])

    # --- Exibi√ß√£o das Features de Entrada ---
    with st.expander("üì• Features de Entrada do Aluno"):
        st.write('**Dados do Aluno Inseridos:**')
        st.dataframe(input_df, use_container_width=True)

    # --- Prepara√ß√£o dos Dados para o Modelo ---
    # Combinar input do usu√°rio com o dataset original para garantir consist√™ncia no encoding
    # Assegura que todas as colunas de X_display (exceto target) estejam presentes
    # e na ordem correta para input_df antes de concatenar.
    
    # Alinhar colunas do input_df com X_display
    input_df_aligned = input_df.reindex(columns=X_display.columns)
    
    combined_data_for_encoding = pd.concat([input_df_aligned, X_display], axis=0)

    # Identificar colunas categ√≥ricas (object ou category dtype) para one-hot encoding
    # Isso √© mais robusto do que fixar uma lista de colunas para encode.
    categorical_cols_to_encode = combined_data_for_encoding.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # Realizar o one-hot encoding
    if categorical_cols_to_encode:
        df_encoded = pd.get_dummies(combined_data_for_encoding, columns=categorical_cols_to_encode, prefix=categorical_cols_to_encode)
    else:
        df_encoded = combined_data_for_encoding.copy() # Nenhuma coluna categ√≥rica para encodar

    # Separar a linha de input (j√° encodada) do restante do dataset (encodado)
    input_row_processed = df_encoded.iloc[[0]]
    X_processed = df_encoded.iloc[1:]
    y_processed = df_raw[target_column] # y n√£o precisa de encoding se j√° for 0/1

    with st.expander("‚öôÔ∏è Dados Preparados para o Modelo"):
        st.write('**Input do Aluno (Ap√≥s Encoding):**')
        st.dataframe(input_row_processed, use_container_width=True)
        st.write('**Vari√°veis Preditoras X (Ap√≥s Encoding - Amostra):**')
        st.dataframe(X_processed.head(), use_container_width=True)
        st.write(f'**Vari√°vel Alvo y ({target_column} - Amostra):**')
        st.dataframe(y_processed.head(), use_container_width=True)
        st.write(f"Dimens√µes de X_processed: {X_processed.shape}")
        st.write(f"Dimens√µes de y_processed: {y_processed.shape}")
        st.write(f"Dimens√µes de input_row_processed: {input_row_processed.shape}")
        
        # Garantir que as colunas do input_row_processed correspondem a X_processed
        if not X_processed.columns.equals(input_row_processed.columns):
            st.error("Inconsist√™ncia de colunas entre os dados de treino e o input do usu√°rio ap√≥s o encoding.")
            st.write("Colunas de X_processed:", X_processed.columns.tolist())
            st.write("Colunas de input_row_processed:", input_row_processed.columns.tolist())
            
            # Tentativa de reconcilia√ß√£o (adicionar colunas faltantes com 0, remover extras)
            # Isso pode ocorrer se uma categoria no input n√£o existia no X_raw original.
            # Ou se uma categoria em X_raw n√£o estava no input.
            
            # Adicionar colunas faltantes no input_row_processed (que est√£o em X_processed)
            for col in X_processed.columns:
                if col not in input_row_processed.columns:
                    input_row_processed[col] = 0
            
            # Remover colunas extras do input_row_processed (que n√£o est√£o em X_processed)
            for col in input_row_processed.columns:
                if col not in X_processed.columns:
                    input_row_processed = input_row_processed.drop(columns=[col])
            
            # Reordenar colunas do input_row_processed para bater com X_processed
            input_row_processed = input_row_processed[X_processed.columns]

            st.warning("Tentativa de reconcilia√ß√£o de colunas aplicada. Verifique os dados abaixo.")
            st.write('**Input do Aluno (Ap√≥s Reconcilia√ß√£o e Encoding):**')
            st.dataframe(input_row_processed, use_container_width=True)
            
            if not X_processed.columns.equals(input_row_processed.columns):
                 st.error("Falha na reconcilia√ß√£o de colunas. O modelo pode n√£o funcionar corretamente.")
                 st.stop()


    # --- Treinamento do Modelo e Infer√™ncia ---
    st.subheader('üöÄ Resultado da Previs√£o')
    try:
        # Dividir os dados carregados em treino e teste para avalia√ß√£o (opcional, mas bom para ter uma ideia da performance)
        # X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42, stratify=y_processed if y_processed.nunique() > 1 else None)

        # Treinar o modelo com TODOS os dados carregados (X_processed, y_processed) para a predi√ß√£o no input do usu√°rio
        model = RandomForestClassifier(random_state=42, class_weight='balanced') # class_weight para datasets desbalanceados
        model.fit(X_processed, y_processed)

        # Fazer predi√ß√£o na linha de input do usu√°rio
        prediction = model.predict(input_row_processed)
        prediction_proba = model.predict_proba(input_row_processed)

        # --- Exibir Resultados da Predi√ß√£o ---
        status_aluno = np.array(['N√£o Evadir√°', 'Evadir√°'])
        
        df_prediction_proba = pd.DataFrame(prediction_proba, columns=status_aluno)

        st.write('**Probabilidades de Evas√£o:**')
        st.dataframe(df_prediction_proba,
                     column_config={
                         'N√£o Evadir√°': st.column_config.ProgressColumn(
                             'N√£o Evadir√°',
                             help="Probabilidade do aluno N√ÉO evadir.",
                             format="%.2f%%", # Formato de porcentagem
                             min_value=0,
                             max_value=1, # Probabilidade √© entre 0 e 1
                         ),
                         'Evadir√°': st.column_config.ProgressColumn(
                             'Evadir√°',
                             help="Probabilidade do aluno EVADIR.",
                             format="%.2f%%",
                             min_value=0,
                             max_value=1,
                         ),
                     }, hide_index=True, use_container_width=True)

        # Destacar a predi√ß√£o
        resultado_final = status_aluno[prediction][0]
        if resultado_final == 'Evadir√°':
            st.error(f'**Predi√ß√£o Final: {resultado_final}** üòü')
            st.warning("Aten√ß√£o: Este aluno apresenta risco de evas√£o. Considere a√ß√µes preventivas.")
        else:
            st.success(f'**Predi√ß√£o Final: {resultado_final}** üòä')
            st.balloons()

        # --- (Opcional) Feature Importance ---
        with st.expander("üí° Import√¢ncia das Features (do modelo treinado)"):
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                feature_names = X_processed.columns
                df_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
                df_importance = df_importance.sort_values(by='Importance', ascending=False)
                
                st.bar_chart(df_importance.set_index('Feature'), use_container_width=True)
            else:
                st.info("O modelo selecionado n√£o suporta a extra√ß√£o direta de import√¢ncia das features.")

    except Exception as e:
        st.error(f"Ocorreu um erro durante o treinamento ou predi√ß√£o: {e}")
        st.error("Verifique se os dados de entrada est√£o corretos e se o dataset carregado √© adequado.")
        # st.exception(e) # Para debugging mais detalhado

else:
    st.warning("O dataset n√£o p√¥de ser carregado. O aplicativo n√£o pode continuar.")

st.sidebar.markdown("---")
st.sidebar.info("Desenvolvido como exemplo de app de Machine Learning com Streamlit.")

